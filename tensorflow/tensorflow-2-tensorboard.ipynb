{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## 可视化工具(tensorboard)\ntensorflow不仅仅是一个计算图软件，其还包含了tensorboard可视化工具，安装tensorflow的时候会默认安装，使用方法非常简单，使用writer \u003d tf.summary.FileWriter(\u0027./graph\u0027, sess.graph)就能够创建一个文件写入器，./graph是存储目录，sess.graph表示读入的图结构。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "5\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import tensorflow as tf\na \u003d tf.constant(2)\nb \u003d tf.constant(3)\nx \u003d tf.add(a, b)\nwith tf.Session() as sess:\n    writer \u003d tf.summary.FileWriter(\u0027./graphs\u0027, sess.graph)\n    print(sess.run(x))\nwriter.close()  # close the writer when you’re done using it"
    },
    {
      "cell_type": "markdown",
      "source": "然后打开终端，运行程序，接着输入`tensorboard --logdir\u003d\"./graphs\"`，然后点击提示信息中的网站，就能够进入tensorboard，可以得到下面的结果。\n![tensorboard](https://pic2.zhimg.com/80/v2-f326d404c78795e13828efa053dd17b5_hd.png)\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 常数类型(Constant types)\n- 能够通过下面这个方式创造一个常数\n- tf.constant(value, dtype\u003dNone, shape\u003dNone, name\u003d\u0027Const\u0027, verify_shape\u003dFalse)",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[[0 2]\n [4 6]]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "a \u003d tf.constant([2,2], name\u003d\u0027a\u0027)\nb \u003d tf.constant([[0,1], [2,3]], name\u003d\u0027b\u0027)\nx \u003d tf.multiply(a, b, name\u003d\u0027dot_production\u0027)\nwith tf.Session() as sess:\n    print(sess.run(x))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "这跟numpy里面的是差不多的，同时还有一些特殊值的常量创建。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[[ 0.  0.]\n [ 0.  0.]]\n[[0 0 0]\n [0 0 0]]\n[[ 1.  1.]\n [ 1.  1.]]\n[[1 1 1]\n [1 1 1]]\n[[8 8 8]\n [8 8 8]]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "shape \u003d [2,2]\nsess \u003d tf.Session()\n# zeros()创建shape.x * shape.y的矩阵\nprint(sess.run(tf.zeros(shape, dtype\u003dtf.float32, name\u003dNone)))\ntensor\u003d[[2,4,4],[1,3,6]]\n\n# zeros_like()创建全0矩阵，形状和tensor一样\nprint(sess.run(tf.zeros_like(tensor, dtype\u003dNone, name\u003dNone, optimize\u003dTrue)))\nprint(sess.run(tf.ones(shape, dtype\u003dtf.float32, name\u003dNone)))\nprint(sess.run(tf.ones_like(tensor, dtype\u003dNone, name\u003dNone, optimize\u003dTrue)))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[[8 8 8]\n [8 8 8]]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# tf.fill(dims, value, name\u003dNone) --用value填充形状为dims的张量\n# 参数说明:\n# dims: 输出张量的形状\n# value: 填充返回的张量的值\nprint(sess.run(tf.fill([2, 3], 8)))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[ 10.  11.  12.  13.]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# tf.linspace(start, stop, num, name\u003dNone)\nprint(sess.run(tf.linspace(10.0, 13.0, 4)))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[ 3  6  9 12 15 18]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# tf.range(start, limit\u003dNone, delta\u003d1, dtype\u003dNone, name\u003d\u0027range\u0027)\nprint(sess.run(tf.range(3, limit\u003d18, delta\u003d3)))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 除此之外还可以产生一些随机数\n```\n# 正态分布随机数，均值mean,标准差stddev\ntf.random_normal(shape, mean\u003d0.0, stddev\u003d1.0, dtype\u003dtf.float32, seed\u003dNone, name\u003dNone)\n# 截断正态分布随机数，均值mean,标准差stddev,不过只保留[mean-2stddev,mean+2stddev]范围内的随机数\ntf.truncated_normal(shape, mean\u003d0.0, stddev\u003d1.0, dtype\u003dtf.float32, seed\u003dNone,\nname\u003dNone)\n# 均匀分布随机数，范围为[minval,maxval]\ntf.random_uniform(shape, minval\u003d0, maxval\u003dNone, dtype\u003dtf.float32, seed\u003dNone,\nname\u003dNone)\n# 沿着张量value的第一维进行随机重新排列\ntf.random_shuffle(value, seed\u003dNone, name\u003dNone)\n# 随机地将张量value裁剪为给定的大小\ntf.random_crop(value, size, seed\u003dNone, name\u003dNone)\n# 从多项式分布logits中抽取num_samples个样本.\ntf.multinomial(logits, num_samples, seed\u003dNone, name\u003dNone)\n# 从每个给定的 Gamma distribution(s) 中绘制 shape 样本.\ntf.random_gamma(shape, alpha, beta\u003dNone, dtype\u003dtf.float32, seed\u003dNone, name\u003dNone)\n```\n- 例如：\n```\nsamples \u003d tf.random_gamma([10], [0.5, 1.5]) \n# samples 的形状为[10, 2], 其中每个 slice [:, 0] 和 [:, 1] 表示从每个分布中抽取的样本\nsamples \u003d tf.random_gamma([7, 5], [0.5, 1.5]) \n# samples 形状为[7, 5, 2], 其中每个 slice [:, :, 0] 和 [:, :, 1] 表示从两个分布中的每一个中抽取 7x5 个样本\nsamples \u003d tf.random_gamma([30], [[1.],[3.],[5.]], beta\u003d[[3., 4.]]) \n# samples 形状为 [30, 3, 2], 每个 3x2 分布有30个样本\n```",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "另外tensorflow和numpy的数据类型可以通用，也就是说",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\ntf.ones([2, 2], np.float32)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n",
          "is_executing": false
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "data": {
            "text/plain": "\u003ctf.Tensor \u0027ones_2:0\u0027 shape\u003d(2, 2) dtype\u003dfloat32\u003e"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "#### 最好不要使用python自带的数据类型，同时在使用numpy数据类型的时候要小心，因为未来可能tensorflow的数据类型和numpy不再兼容。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 变量(Variable)\n使用常量会存在什么问题呢？常量会存在计算图的定义当中，如果常量过多，这会使得加载计算图变得非常慢，同时常量的值不可改变，所以引入了变量。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "source": "a \u003d tf.Variable(2, name\u003d\u0027scalar\u0027)\nb \u003d tf.Variable([2, 3], name\u003d\u0027vector\u0027)\nc \u003d tf.Variable([[0, 1], [2, 3]], name\u003d\u0027matrix\u0027)\nw \u003d tf.Variable(tf.zeros([784, 10]), name\u003d\u0027weight\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "变量有着下面几个操作\n```\nx \u003d tf.Variable()\nx.initializer # 初始化\nx.eval() # 读取里面的值\nx.assign() # 分配值给这个变量\n```",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "注意一点，在使用变量之前必须对其进行初始化，初始化可以看作是一种变量的分配值操作。最简单的初始化方式是一次性初始化所有的变量",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "source": "init \u003d tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "也可以对某一部分变量进行初始化",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "None\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "init_ab \u003d tf.variables_initializer([a, b], name\u003d\u0027init_ab\u0027)\nwith tf.Session() as sess:\n    sess.run(init_ab)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "或者是对某一个变量进行初始化",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [],
      "source": "w \u003d tf.Variable(tf.zeros([784, 10]))\nwith tf.Session() as sess:\n    sess.run(w.initializer)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "如果我们想取出变量的值，有两种方法",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[[-0.95718139 -0.44025454  0.74425966  0.90783101  1.92811644 -1.23942387\n  -0.5437609  -0.38250542 -0.25278467  0.53650796]\n [-0.20639697  0.09634554 -0.97924918  0.65590286 -0.59741789  0.72083384\n   0.08172197  0.11697232 -0.12097789 -0.59242022]\n [ 1.69721115  1.22957861 -0.51178795  0.7769385   1.58861959  0.45306814\n  -0.86427718  0.64466608  1.5474869  -1.05312073]\n [-0.39219511  0.49143392  0.35518053 -0.87263775  1.71564329  0.91315299\n   0.67178315 -0.64709389 -0.51290148  0.63789964]\n [-1.39125645 -0.33293372 -0.28284857 -0.07524792  0.42671156 -0.89730573\n  -0.95670503  0.27647999 -0.58710933  1.34452248]\n [ 0.69753832  0.85837597 -1.39729309  0.55970442 -1.2486279  -0.82782286\n  -0.59798783  0.90180582  0.61606443  1.78436077]\n [ 0.94495797  0.13594955 -0.51260149 -0.47672337 -0.60010576  0.64251441\n  -0.27183887 -1.1965642  -1.3056109   0.22318153]\n [ 1.31254125  0.29588953 -1.42722034  1.03387058  1.98050785 -0.73330659\n  -0.72953737  0.37646601  0.17473647 -0.49377769]\n [-0.19598518  1.27534044  0.44709879  1.48152161 -0.33126816 -1.56247163\n  -0.85370022 -0.90415955  1.11878192 -0.79377878]\n [-0.68823135  1.7871418   1.24609041  0.85337216  1.04367483  0.67271161\n   0.32454488 -0.88291365  0.01013429  0.28430626]]\n[[-0.95718139 -0.44025454  0.74425966  0.90783101  1.92811644 -1.23942387\n  -0.5437609  -0.38250542 -0.25278467  0.53650796]\n [-0.20639697  0.09634554 -0.97924918  0.65590286 -0.59741789  0.72083384\n   0.08172197  0.11697232 -0.12097789 -0.59242022]\n [ 1.69721115  1.22957861 -0.51178795  0.7769385   1.58861959  0.45306814\n  -0.86427718  0.64466608  1.5474869  -1.05312073]\n [-0.39219511  0.49143392  0.35518053 -0.87263775  1.71564329  0.91315299\n   0.67178315 -0.64709389 -0.51290148  0.63789964]\n [-1.39125645 -0.33293372 -0.28284857 -0.07524792  0.42671156 -0.89730573\n  -0.95670503  0.27647999 -0.58710933  1.34452248]\n [ 0.69753832  0.85837597 -1.39729309  0.55970442 -1.2486279  -0.82782286\n  -0.59798783  0.90180582  0.61606443  1.78436077]\n [ 0.94495797  0.13594955 -0.51260149 -0.47672337 -0.60010576  0.64251441\n  -0.27183887 -1.1965642  -1.3056109   0.22318153]\n [ 1.31254125  0.29588953 -1.42722034  1.03387058  1.98050785 -0.73330659\n  -0.72953737  0.37646601  0.17473647 -0.49377769]\n [-0.19598518  1.27534044  0.44709879  1.48152161 -0.33126816 -1.56247163\n  -0.85370022 -0.90415955  1.11878192 -0.79377878]\n [-0.68823135  1.7871418   1.24609041  0.85337216  1.04367483  0.67271161\n   0.32454488 -0.88291365  0.01013429  0.28430626]]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "w \u003d tf.Variable(tf.truncated_normal([10, 10], name\u003d\u0027normal\u0027))\nwith tf.Session() as sess:\n    sess.run(w.initializer)\n    print(w.eval()) # 方法一\n    print(sess.run(w)) # 方法二",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "下面看看这个小程序",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "10\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "w \u003d tf.Variable(10)\nw.assign(100)\nwith tf.Session() as sess:\n    sess.run(w.initializer)\n    print(w.eval())",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "上面这个程度会得到10,这是因为我们虽然定义了assign操作，但是tensorflow是在session中执行操作，所以我们需要执行assign操作。",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "100\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "w \u003d tf.Variable(10)\nassign_op \u003d w.assign(100)\nwith tf.Session() as sess:\n    sess.run(w.initializer)\n    sess.run(assign_op)\n    print(w.eval())",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "另外tensorflow的每个session是相互独立的，我们可以看看下面这个例子",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "20\n8\n120\n-42\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "W \u003d tf.Variable(10)\nsess1 \u003d tf.Session()\nsess2 \u003d tf.Session()\nsess1.run(W.initializer)\nsess2.run(W.initializer)\nprint(sess1.run(W.assign_add(10))) # \u003e\u003e 20\nprint(sess2.run(W.assign_sub(2))) # \u003e\u003e 8\nprint(sess1.run(W.assign_add(100))) # \u003e\u003e 120\nprint(sess2.run(W.assign_sub(50))) # \u003e\u003e -42\nsess1.close()\nsess2.close()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "你也可以根据一个变量来定义一个变量",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "w \u003d tf.Variable(tf.truncated_normal([700, 10]))\nu \u003d tf.Variable(w * 2)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 占位符(Placeholders)\ntensorflow中一般有两步，第一步是定义图，第二步是在session中进行图中的计算。对于图中我们暂时不知道值的量，我们可以定义为占位符，之后再用`feed_dict`去赋值。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "定义占位符的方式非常简单\n```\ntf.placeholder(dtype, shape\u003dNone, name\u003dNone)\n```\ndtype是必须要指定的参数，shape如果是None，说明任何大小的tensor都能够接受，使用shape\u003dNone很容易定义好图，但是在debug的时候这将成为噩梦，所以最好是指定好shape。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[ 6.  7.  8.]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "a \u003d tf.placeholder(tf.float32, shape\u003d[3])\nb \u003d tf.constant([5, 5, 5], tf.float32)\nc \u003d a + b\nwith tf.Session() as sess:\n    print(sess.run(c, feed_dict\u003d{a: [1, 2, 3]}))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "除此之外，也可以给tensorflow中的运算进行feed操作，如下",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "15\n6\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "a \u003d tf.add(2, 3)\nb \u003d tf.multiply(a, 3)\nwith tf.Session() as sess:\n    print(sess.run(b))\n    print(sess.run(b, feed_dict\u003d{a: 2}))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### lazy loading\nlazy loading是指你推迟变量的创建直到你必须要使用他的时候。下面我们看看一般的loading和lazy loading的区别。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "source": "# normal loading\nx \u003d tf.Variable(10, name\u003d\u0027x\u0027)\ny \u003d tf.Variable(20, name\u003d\u0027y\u0027)\nz \u003d tf.add(x, y)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for _ in range(10):\n        sess.run(z)\n\n# lazy loading\nx \u003d tf.Variable(10, name\u003d\u0027x\u0027)\ny \u003d tf.Variable(20, name\u003d\u0027y\u0027)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for _ in range(10):\n        sess.run(tf.add(x, y))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "normal loading 会在图中创建x和y变量，同时创建x+y的运算，而lazy loading只会创建x和y两个变量。这不是一个bug，那么问题在哪里呢？\n\nnormal loading在session中不管做多少次x+y，只需要执行z定义的加法操作就可以了，而lazy loading在session中每进行一次x+y，就会在图中创建一个加法操作，如果进行1000次x+y的运算，normal loading的计算图没有任何变化，而lazy loading的计算图会多1000个节点，每个节点都表示x+y的操作。\n\n看到了吗，这就是lazy loading造成的问题，这会严重影响图的读入速度。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "anaconda",
      "language": "python",
      "display_name": "Anaconda"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}